{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class DataLine:\n",
    "    def __init__(self,\n",
    "                 page_number: str = None,  #:Nстраницы\n",
    "                 line_number: str = None,  #:Nстроки, сквозной\n",
    "                 first_symbol: str = None,  #:Nсимвола, начального, сквозной\n",
    "                 int_from_prev: str = None,  #:дельта-v-coord-up\n",
    "                 int_from_next: str = None,  #:дельта-v-coord-down\n",
    "                 h_left: str = None,  #:h-coord начала\n",
    "                 h_right: str = None,  #:h-coord конца + 1\n",
    "                 v: str = None,  #:v-coord\n",
    "                 font0_size: str = None,  #:font-height0\n",
    "                 font0_name: str = '',  #:font-name0\n",
    "                 font1_size: str = None,  #:font-height1\n",
    "                 font1_name: str = '',  #:font-name1\n",
    "                 text: str = None,  #:TEXT\n",
    "                 ):\n",
    "        self.page_number = int(page_number) if len(page_number) else 0\n",
    "        self.line_number = int(line_number) if len(line_number) else 0\n",
    "        self.first_symbol = int(first_symbol) if len(first_symbol) else 0\n",
    "\n",
    "        self.int_from_prev = int(int_from_prev) if len(int_from_prev) else 0\n",
    "        self.int_from_next = int(int_from_next) if len(int_from_next) else 0\n",
    "\n",
    "        self.h_left = int(h_left) if len(h_left) else 0\n",
    "        self.h_right = int(h_right) if len(h_right) else 0\n",
    "        self.v = int(v) if len(v) else 0\n",
    "\n",
    "        self.font0_size = int(font0_size) if len(font0_size) else 0\n",
    "        self.font0_name = font0_name\n",
    "        self.font1_size = int(font1_size) if len(font1_size) else 0\n",
    "        self.font1_name = font1_name\n",
    "\n",
    "        self.text = text\n",
    "\n",
    "        self.label = '?'\n",
    "\n",
    "class State(Enum):\n",
    "    NEUTRAL = 0\n",
    "    PARAGRAPH = 1\n",
    "    BUKVITSA = 2\n",
    "\n",
    "class Label(Enum):\n",
    "    PAR_STARTS = 'A'\n",
    "    PAR_CONTINUES = 'B'\n",
    "    HEADER = 'C'\n",
    "    BUKVITSA = 'D'\n",
    "    LIST = 'E'\n",
    "    OTHER = '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from reportlab.pdfgen import canvas\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "import sys\n",
    "\n",
    "\n",
    "def main(journal_name, paper_name):\n",
    "    # чтение строк из txt-файла\n",
    "    input_file_name = f'originals/{journal_name}/{paper_name}'\n",
    "    data = []\n",
    "\n",
    "    with open(os.path.join(os.path.dirname(os.path.curdir), input_file_name + '.txt'), \"r\", encoding=\"utf8\") as read_file:\n",
    "        for line in read_file:\n",
    "            splitted = line.replace('\\n', '').split(':')\n",
    "            # print(splitted, \"LEN\", len(splitted))\n",
    "\n",
    "            if len(splitted) > 13:\n",
    "                rt = ':'.join(splitted[12:])\n",
    "                data_line = DataLine(*splitted[:12], rt)\n",
    "            elif len(splitted) == 13:\n",
    "                data_line = DataLine(*splitted)\n",
    "            else:\n",
    "                pass\n",
    "                assert len(splitted) >= 12, 'must have at least 12 elements'\n",
    "            data.append(data_line)\n",
    "\n",
    "    # границы абзацев\n",
    "    margin_lefts = np.array([x.h_left for x in data])\n",
    "\n",
    "    unique_margin_lefts, pos_margin_lefts = np.unique(margin_lefts, return_inverse=True)\n",
    "    counts_margin_lefts = np.bincount(pos_margin_lefts)\n",
    "    sorted_margin_lefts = np.argsort(counts_margin_lefts)[::-1]\n",
    "\n",
    "    margin_rights = np.array([x.h_right for x in data])\n",
    "\n",
    "    unique_margin_rights, pos_margin_rights = np.unique(margin_rights, return_inverse=True)\n",
    "    counts_margin_rights = np.bincount(pos_margin_rights)\n",
    "    sorted_margin_rights = np.argsort(counts_margin_rights)[::-1]\n",
    "\n",
    "    EPS = 4\n",
    "    EPS_FONT = 2\n",
    "\n",
    "    left_keys = list()\n",
    "    left_indents = defaultdict(int)\n",
    "    for a, b in zip(unique_margin_lefts[sorted_margin_lefts[:15]], counts_margin_lefts[sorted_margin_lefts[:15]]):\n",
    "        index = -1\n",
    "        # print(a, b)\n",
    "        for l in range(a - EPS, a + EPS + 1):\n",
    "            if l in left_indents:\n",
    "                index = l\n",
    "        if index != -1:\n",
    "            left_indents[index] += b\n",
    "        else:\n",
    "            left_indents[a] += b\n",
    "            left_keys.append(a)\n",
    "\n",
    "    left_len = 1\n",
    "    left_sum = left_indents[left_keys[0]]\n",
    "    while True:\n",
    "        if left_indents[left_keys[left_len]] * 1.1 >= left_indents[left_keys[left_len - 1]]:\n",
    "            left_sum += left_indents[left_keys[left_len]]\n",
    "            left_len += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(left_len)\n",
    "\n",
    "    right_keys = list()\n",
    "    right_indents = defaultdict(int)\n",
    "    for a, b in zip(unique_margin_rights[sorted_margin_rights[:15]], counts_margin_rights[sorted_margin_rights[:15]]):\n",
    "        index = -1\n",
    "        # print(a, b)\n",
    "        for l in range(a - EPS, a + EPS + 1):\n",
    "            if l in right_indents:\n",
    "                index = l\n",
    "        if index != -1:\n",
    "            right_indents[index] += b\n",
    "        else:\n",
    "            right_indents[a] += b\n",
    "            right_keys.append(a)\n",
    "\n",
    "    right_len = 1\n",
    "    right_sum = right_indents[right_keys[0]]\n",
    "    while True:\n",
    "        if right_indents[right_keys[right_len]] * 1.1 >= right_indents[right_keys[right_len - 1]]:\n",
    "            right_sum += right_indents[right_keys[left_len]]\n",
    "            right_len += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(right_len)\n",
    "\n",
    "    if left_len != right_len:\n",
    "        print(f'Error for detecting columns borders for {input_file_name}')\n",
    "        return\n",
    "\n",
    "    LEFT_BORDERS = np.sort(left_keys[:left_len])\n",
    "    RIGHT_BORDERS = np.sort(right_keys[:right_len])\n",
    "\n",
    "    # regular font\n",
    "\n",
    "    font_names = defaultdict(int)\n",
    "\n",
    "    REGULAR_FONT_NAME = None\n",
    "    REGULAR_FONT_SIZE = None\n",
    "    max_font_name = 0\n",
    "    MAX_FONT_SIZE = 0\n",
    "    MAX_FONT_COUNT = 0\n",
    "\n",
    "    for x in data:\n",
    "        if x.font0_size > MAX_FONT_SIZE:\n",
    "            MAX_FONT_SIZE = x.font0_size\n",
    "            MAX_FONT_COUNT = len(x.text)\n",
    "        elif x.font0_size == MAX_FONT_SIZE:\n",
    "            MAX_FONT_COUNT += len(x.text)\n",
    "\n",
    "        if min(abs(x.h_left - LEFT_BORDERS)) <= EPS and min(abs(x.h_right - RIGHT_BORDERS)) <= EPS:\n",
    "            # чтобы уж наверняка, выбираем только полные строки\n",
    "            font_names[(x.font0_name, x.font0_size)] += 1\n",
    "            font_names[(x.font1_name, x.font1_size)] += 1\n",
    "            if font_names[(x.font0_name, x.font0_size)] > max_font_name:\n",
    "                max_font_name = font_names[(x.font0_name, x.font0_size)]\n",
    "                REGULAR_FONT_NAME = x.font0_name\n",
    "                REGULAR_FONT_SIZE = x.font0_size\n",
    "            if font_names[(x.font1_name, x.font1_size)] > max_font_name:\n",
    "                max_font_name = font_names[(x.font1_name, x.font1_size)]\n",
    "                REGULAR_FONT_NAME = x.font1_name\n",
    "                REGULAR_FONT_SIZE = x.font1_size\n",
    "\n",
    "    # bukvitsa\n",
    "    IS_BUKVITSA = (MAX_FONT_COUNT == 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def process_line(line, cur_state):\n",
    "        # ищем колонку, куда помещается строчка\n",
    "        ind_block = -1\n",
    "        for i in range(len(LEFT_BORDERS)):\n",
    "            l = LEFT_BORDERS[i]\n",
    "            r = RIGHT_BORDERS[i]\n",
    "            if l - EPS <= line.h_left and line.h_right <= r + EPS:\n",
    "                ind_block = i\n",
    "\n",
    "        # если колонка не обнаружена, выходим\n",
    "        if ind_block == -1:\n",
    "            return Label[\"OTHER\"], State[\"NEUTRAL\"]\n",
    "\n",
    "        # иначе колонка найдена\n",
    "\n",
    "        is_font0_same = abs(line.font0_size - REGULAR_FONT_SIZE) <= EPS_FONT\n",
    "        is_font1_same = abs(line.font1_size - REGULAR_FONT_SIZE) <= EPS_FONT\n",
    "\n",
    "        is_font0_regular = line.font0_name == REGULAR_FONT_NAME\n",
    "        is_font1_regular = line.font1_name == REGULAR_FONT_NAME\n",
    "\n",
    "        is_aligned_left = abs(LEFT_BORDERS[ind_block] - line.h_left) <= EPS\n",
    "        is_aligned_right = abs(RIGHT_BORDERS[ind_block] - line.h_right) <= EPS\n",
    "\n",
    "        bukvitsa_size = MAX_FONT_SIZE if IS_BUKVITSA else MAX_FONT_SIZE + 3 * EPS\n",
    "\n",
    "        if is_aligned_left and is_aligned_right:\n",
    "            if is_font0_same or is_font1_same:\n",
    "                return Label[\"PAR_CONTINUES\"], State[\"PARAGRAPH\"]\n",
    "            else:\n",
    "                return Label[\"OTHER\"], State[\"NEUTRAL\"]\n",
    "        elif is_aligned_left:\n",
    "            # конец абзаца\n",
    "            if is_font0_same or is_font1_same:\n",
    "                return Label[\"PAR_CONTINUES\"], State[\"PARAGRAPH\"]\n",
    "            # буквица\n",
    "            elif abs(line.font0_size - bukvitsa_size) <= EPS or abs(line.font1_size - bukvitsa_size) <= EPS:\n",
    "                return Label[\"BUKVITSA\"], State[\"BUKVITSA\"]\n",
    "            # заголовок\n",
    "            else:\n",
    "                if (not is_font0_regular) or (not is_font1_regular):\n",
    "                    return Label[\"HEADER\"], State[\"NEUTRAL\"]\n",
    "                else:\n",
    "                    return Label[\"OTHER\"], State[\"NEUTRAL\"]\n",
    "        elif is_aligned_right:\n",
    "            if cur_state == State[\"BUKVITSA\"]:\n",
    "                return Label[\"PAR_CONTINUES\"], State[\"PARAGRAPH\"]\n",
    "            elif is_font0_same or is_font1_same:\n",
    "                tokens = line.text.split()\n",
    "                if len(tokens) > 0:\n",
    "                    first_token = tokens[0]\n",
    "                    filtered = ''.join(list(filter(lambda x: x in 'ЁЙЦУКЕНГШЩЗХЪФЫВАПРОЛДЖЭЯЧСМИТЬБЮ', first_token)))\n",
    "                    if len(filtered) > 0:\n",
    "                        return Label[\"PAR_STARTS\"], State[\"PARAGRAPH\"]\n",
    "                    else:\n",
    "                        return Label[\"LIST\"], State[\"PARAGRAPH\"]\n",
    "                else:\n",
    "                    return Label[\"OTHER\"], State[\"NEUTRAL\"]\n",
    "            # заголовок\n",
    "            else:\n",
    "                return Label[\"HEADER\"], State[\"NEUTRAL\"]\n",
    "        else:\n",
    "            if (not is_font0_regular) and (not is_font1_regular):\n",
    "                return Label[\"HEADER\"], State[\"NEUTRAL\"]\n",
    "            else:\n",
    "                tokens = line.text.split()\n",
    "                if len(tokens) > 0:\n",
    "                    first_token = tokens[0]\n",
    "                    filtered = ''.join(list(filter(lambda x: x in 'ЁЙЦУКЕНГШЩЗХЪФЫВАПРОЛДЖЭЯЧСМИТЬБЮ', first_token)))\n",
    "                    if len(filtered) > 0:\n",
    "                        return Label[\"OTHER\"], State[\"NEUTRAL\"]\n",
    "                    else:\n",
    "                        return Label[\"LIST\"], State[\"PARAGRAPH\"]\n",
    "                else:\n",
    "                    return Label[\"OTHER\"], State[\"NEUTRAL\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    output_file_name_txt = f'processed/{journal_name}/{paper_name}_l.txt'\n",
    "    with open(os.path.join(os.path.dirname(os.path.curdir), output_file_name_txt), 'w', encoding='utf8') as output:\n",
    "        cur_state = State[\"NEUTRAL\"]\n",
    "\n",
    "        PAR_INDENTS = defaultdict(int)\n",
    "\n",
    "        for line in data:\n",
    "            label, cur_state = process_line(line, cur_state)\n",
    "            line.label = label.value\n",
    "            if label == Label[\"PAR_STARTS\"]:\n",
    "                index = line.h_left\n",
    "                for l in range(line.h_left - EPS, line.h_left + EPS + 1):\n",
    "                    if l in PAR_INDENTS:\n",
    "                        index = l\n",
    "                PAR_INDENTS[index] += 1\n",
    "\n",
    "        for line in data:\n",
    "            if line.label == Label[\"OTHER\"].value:\n",
    "                # print('YES', line.text)\n",
    "                index = line.h_left\n",
    "                for l in range(line.h_left - EPS, line.h_left + EPS + 1):\n",
    "                    if l in PAR_INDENTS:\n",
    "                        index = l\n",
    "                # print(index)\n",
    "                if PAR_INDENTS[index] > 1:\n",
    "                    line.label = Label[\"PAR_STARTS\"].value\n",
    "\n",
    "        for line in data:\n",
    "            line_export = [line.page_number, line.line_number, line.first_symbol, line.int_from_prev,\n",
    "                           line.int_from_next, line.h_left, line.h_right, line.v,\n",
    "                           line.font0_size, line.font0_name, line.font1_size, line.font1_name,\n",
    "                           line.label, line.text]\n",
    "\n",
    "            line_export = ':'.join([str(y) for y in line_export])\n",
    "            output.write(f'{line_export}\\n')\n",
    "\n",
    "    output_file_name_pdf = f'processed/{journal_name}/{paper_name}_l.pdf'\n",
    "\n",
    "    color_dict = {'A': (1.0, 0.0, 0.0),\n",
    "                  'B': (0.0, 0.1, 0.0),\n",
    "                  'C': (0.0, 0.0, 1.0),\n",
    "                  'D': (1.0, 0.0, 1.0),\n",
    "                  'E': (1.0, 1.0, 0.0),\n",
    "                  '?': (0.5, 0.5, 0.5),\n",
    "                  }\n",
    "    input_file = PdfFileReader(open(os.path.join(os.path.dirname(os.path.curdir), input_file_name + '.pdf'), \"rb\"))\n",
    "    output_file = PdfFileWriter()\n",
    "    cur_page = 0\n",
    "    input_page = input_file.getPage(cur_page)\n",
    "\n",
    "    c = canvas.Canvas('watermark.pdf')\n",
    "    for line in data:\n",
    "\n",
    "        if line.page_number - 1 == cur_page:\n",
    "            # new page == old page\n",
    "            c.setStrokeColorRGB(*color_dict[line.label])\n",
    "            c.rect(line.h_left, line.v, line.h_right - line.h_left, 8, stroke=1, fill=0)\n",
    "\n",
    "            # input_page.mergePage(watermark.getPage(0))\n",
    "        else:\n",
    "            c.save()\n",
    "            watermark = PdfFileReader(open(\"watermark.pdf\", \"rb\"))\n",
    "            input_page.mergePage(watermark.getPage(0))\n",
    "            output_file.addPage(input_page)\n",
    "\n",
    "            cur_page = line.page_number - 1\n",
    "            input_page = input_file.getPage(cur_page)\n",
    "\n",
    "            c = canvas.Canvas('watermark.pdf')\n",
    "            c.setStrokeColorRGB(*color_dict[line.label])\n",
    "            c.rect(line.h_left, line.v, line.h_right - line.h_left, 8, stroke=1, fill=0)\n",
    "\n",
    "    c.save()\n",
    "    watermark = PdfFileReader(open(\"watermark.pdf\", \"rb\"))\n",
    "    input_page.mergePage(watermark.getPage(0))\n",
    "    output_file.addPage(input_page)\n",
    "\n",
    "    with open(os.path.join(os.curdir, output_file_name_pdf), \"wb\") as o:\n",
    "        output_file.write(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "main('aerospace', 'y:2015:i:1:p:1-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('processed')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulletin\n",
      "917.txt\n",
      "1\n",
      "4\n",
      "Error for detecting columns borders for originals/bulletin/917\n",
      "acmeology\n",
      "928.txt\n",
      "2\n",
      "2\n",
      "biotechnology\n",
      "y:2013:i:1:p:3-7.txt\n",
      "biopreparations\n",
      "y:2015:i:1:p:4-14.txt\n",
      "1\n",
      "2\n",
      "Error for detecting columns borders for originals/biopreparations/y:2015:i:1:p:4-14\n",
      "aerospace\n",
      "y:2015:i:1:p:1-17.txt\n",
      "1\n",
      "1\n",
      "abgb\n",
      "y:2015:i:1:p:5-19.txt\n",
      "anatomy\n",
      "378.txt\n",
      "1\n",
      "1\n",
      "aaresearch\n",
      "y:2016:i:1:p:5-18.txt\n",
      "1\n",
      "2\n",
      "Error for detecting columns borders for originals/aaresearch/y:2016:i:1:p:5-18\n",
      "accounting\n",
      "y:2016:i:2:p:48-53.txt\n",
      "bricslaw\n",
      "y:2014:i:1:p:4.txt\n",
      "1\n",
      "1\n",
      "almclinmed\n",
      "45.txt\n",
      "3\n",
      "1\n",
      "Error for detecting columns borders for originals/almclinmed/45\n",
      "adi-madi\n",
      "y:1:i:1:p:2014.txt\n",
      "a-surgeon\n",
      "y:2015:i:2:p:3-7.txt\n",
      "agx\n",
      "y:2012:i:4:p:4-12.txt\n",
      "1\n",
      "4\n",
      "Error for detecting columns borders for originals/agx/y:2012:i:4:p:4-12\n",
      "akusherstvo\n",
      "62.txt\n",
      "actabiomedica\n",
      "1281.txt\n",
      "avia\n",
      "1092.txt\n",
      "archaeology\n",
      "y:2013:i:1:p:2-27.txt\n",
      "aterotromboz\n",
      "y:2013:i:1:p:2-8.txt\n",
      "1\n",
      "1\n",
      "bioterapevt\n",
      "y:2015:i:1:p:3-10.txt\n",
      "bibliotekovedenie\n",
      "y:2011:i:2:p:1.txt\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for journal in os.listdir('originals'):\n",
    "    print(journal)\n",
    "    try:\n",
    "        os.mkdir(f'processed/{journal}')\n",
    "    except:\n",
    "        pass\n",
    "    for paper in os.listdir(f'originals/{journal}'):\n",
    "        if paper.endswith('.txt'):\n",
    "            print(paper)\n",
    "            paper_name = paper[:-4]\n",
    "            try:\n",
    "                main(journal, paper_name)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
